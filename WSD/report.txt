Run the given baseline.py, we get the following result:

                            Table 2: Baseline result

                           |  English  |  Spanish  |  Catalan
              ---------------------------------------------------
                Baseline   |   53.5%   |   68.4%   |   67.8%


Then I constructed classifiers with only features in the window (k=10), and did no 
improvement. (No stemming, no punctuation elimination...)
The result is shown in Table 3.

                       Table 3 Naked classifiers' result

                           |  English  |  Spanish  |  Catalan
              ---------------------------------------------------
                LinearSVC  |   60.5%   |   79.3%   |   81.6%
              ---------------------------------------------------
                KNeighbors |   55.3%   |   69.4%   |   71.1%
According to the requirement, based on the original model, we need to add to or 
modifiy the feature plane to get better performance. We also need to reconsider the 
selection of classifier and its parameter, thus the works can be listed as below:

     Feature                               Requirement
-------------------------------------------------------
Final Feature Selection & Modification:

  1. window size K                              10
  2. ignore_U
  3. vector_0_1
  4. add POS-Added
  5. remove_punctuations-Added 
  6. stemming -Added
  7. remove_stop_words -Added
  8. expand_synsets_hypernyms_hyponyms  -Added but not used
  9. probability map feature  -Added
  10. chi_square -Added but not used
  11. pmi 


Default Selection

Feature (3)(4)(5)(6) are selected as precondtion
These feature combinations benefit the Spanish and Catalan model, but does not improve the performance for English. The precision
for English models are decreased. 

                           |  English  |  Spanish  |  Catalan
              ---------------------------------------------------
                LinearSVC  |   60.6%   |   78.9%   |   82.3%

Remove stop words
Removing stop words gives some improvement for Spanish models and English introducing about
1% increase on the percision of English LinearSVC model. Here Catalan is no result because nltk does not 
provide Catalan stop words, and this feature is not applicable for Catalan.
                           |  English  |  Spanish  |  Catalan
              ---------------------------------------------------
                LinearSVC  |   60.7%   |   79.3%   |     -
Do stemming
Stemming gives some improvement, about 1.5% increase for
each of the Spanish models. Since nltk does not provide stemmer for Catalan, this
method is not applicable for Catalan.
                           |  English  |  Spanish  |  Catalan
              ---------------------------------------------------
                LinearSVC  |   62.6%   |   80.8%   |     -

expand_synsets_hypernyms_hyponyms
NLTK does not support synsets of Spanish and Catalan, so they are not included here.
Compared to Table 6, we can observer that so far the expansion with synsets, 
hypernyms and hyponyms doesn't work for the language model. Besides, this feature 
extraction takes much longer time than others
                           |  English  |  Spanish  |  Catalan
              ---------------------------------------------------
                LinearSVC  |   62.6%   |     -     |     -

probability map feature
the probability map feature doesn't introduce much improvement
                           |  English  |  Spanish  |  Catalan
              ---------------------------------------------------
                LinearSVC  |   62.6%   |   80.8%   |   82.4%

The most interesting observation I made was that the maximum impact was offered when the feature list using stemming, stop_word removal were used with very little 
impact by the other feature extracting methods. This may be because the other features may lead sparse data when compared to the impact that the former feature 
extractions methods have on the data
There was a stark difference seen in the precision for English and the other 2 languages and I believe this may be due to sense sparseness that I observed in the
data set which may account for more features for the other 2 languages, Catalan more so